"""Tools for testing LLM decision trees."""

from typing import Literal

import networkx as nx
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from transformers.utils.logging import disable_progress_bar

disable_progress_bar()


def topk_token_probabilities(
    model: AutoModelForCausalLM,
    tokenizer: AutoTokenizer,
    input_text: str,
    k: int = 10,
) -> tuple[torch.tensor, torch.tensor]:
    """Get the K most probable tokens & probabilities the model would select.

    See also `torch.topk`.

    Usage:
        >>> from transformers import AutoModelForCausalLM, AutoTokenizer
        >>> model = AutoModelForCausalLM.from_pretrained(
        ...    "Qwen/Qwen2.5-Coder-0.5B-Instruct", device_map="auto"
        ... )
        >>> tokenizer = AutoTokenizer.from_pretrained(
        ...    "Qwen/Qwen2.5-Coder-0.5B-Instruct", device_map="auto"
        ... )
        >>> input_text = "Here is a list of Python packages.\n\n- "
        >>> topk_token_probabilities(model, tokenizer, input_text)

    Args:
        model: transformers model for causal LM
        tokenizer: transformers tokenizer
        input_text: text previously generated by LLM / inputted by user
        k: the k in "top-k"

    Returns:
        (topk_values, topk_indices): tuple of torch tensors
    """

    input_ids = tokenizer.encode(input_text, return_tensors="pt").to(model.device)

    with torch.no_grad():
        outputs = model(input_ids)
        logits = outputs.logits

    last_token_logits = logits[0, -1, :]
    probabilities = torch.nn.functional.softmax(last_token_logits, dim=-1)

    topk_values, topk_indices = torch.topk(probabilities, k=k)
    return topk_values, topk_indices


def token_decision_tree(
    model: AutoModelForCausalLM,
    tokenizer: AutoTokenizer,
    input_text: str,
    k: int = 3,
    max_depth: int = 2,
) -> nx.DiGraph:
    """Calculate the LLM's top-k token decision tree.

    Args:
        model: transformers model for causal LM
        tokenizer: transformers tokenizer
        input_text: text previously generated by LLM / inputted by user
        k: the k in "top-k"
        max_depth: decision tree depth

    Raises:
        ValueError: if `max_depth` is not an integer greater than 1

    Returns:
        decision_tree: NetworkX digraph decision tree
    """
    if not max_depth >= 1:
        raise ValueError("max depth must be an integer greater than 1")

    decision_tree = nx.balanced_tree(r=k, h=max_depth, create_using=nx.DiGraph)

    input_ids = tokenizer.encode(input_text, return_tensors="np")[-1]
    last_input_id = input_ids[-1]

    decision_tree.nodes[0]["token_id"] = int(last_input_id)
    decision_tree.nodes[0]["token"] = tokenizer.decode(last_input_id)
    decision_tree.nodes[0]["depth"] = 0

    for node_id in decision_tree.nodes():
        current_depth = decision_tree.nodes[node_id]["depth"]

        if current_depth == max_depth:
            traversal = nx.shortest_path(decision_tree, 0, node_id)
            continue

        node_input_text = input_text
        if current_depth != 0:
            traversal = nx.shortest_path(decision_tree, 0, node_id)
            node_input_text += tokenizer.decode(
                [decision_tree.nodes[n]["token_id"] for n in traversal[1:]]
            )

        topk_token_probs, topk_token_ids = topk_token_probabilities(
            model, tokenizer, node_input_text, k=k
        )

        successors = list(decision_tree.successors(node_id))
        topk_tokens = tokenizer.convert_ids_to_tokens(topk_token_ids)

        for successor, token_id, token, prob in zip(
            successors,
            topk_token_ids,
            topk_tokens,
            topk_token_probs,
            strict=True,
        ):
            decision_tree.nodes[successor]["depth"] = current_depth + 1
            decision_tree.nodes[successor]["token_id"] = token_id.item()
            decision_tree.nodes[successor]["token"] = token
            decision_tree.edges[(node_id, successor)]["probability"] = prob

    return decision_tree


def draw_decision_tree(
    decision_tree: nx.DiGraph, label_type: Literal["token", "token_id"] = "token_id"
):
    """Draw the LLM top-k token decision tree."""

    if label_type not in ["token", "token_id"]:
        msg = f"Invalid label type: {label_type}"
        raise ValueError(msg)

    labels = {
        node_id: decision_tree.nodes[node_id][label_type]
        for node_id in decision_tree.nodes
    }

    edge_labels = {
        edge_id: format(decision_tree.edges[edge_id]["probability"], ".2e")
        for edge_id in decision_tree.edges
    }
    layout = nx.multipartite_layout(decision_tree, subset_key="depth")
    nx.draw(decision_tree, pos=layout, with_labels=True, labels=labels)
    nx.draw_networkx_edge_labels(decision_tree, pos=layout, edge_labels=edge_labels)
